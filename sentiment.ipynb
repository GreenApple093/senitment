{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis & AI-Generated Responses for Employee Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: hf_xet in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openai==0.28 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai==0.28) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai==0.28) (3.10.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28) (1.17.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\maury\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->openai==0.28) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.4)\n",
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.22.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.151.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.36.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (4.25.6)\n",
      "Requirement already satisfied: pydantic in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.9.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core->google-generativeai) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->google-generativeai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\maury\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Downloading google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 1.0/1.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.4\n",
      "    Uninstalling google-ai-generativelanguage-0.6.4:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.4\n",
      "  Attempting uninstall: google-generativeai\n",
      "    Found existing installation: google-generativeai 0.5.4\n",
      "    Uninstalling google-generativeai-0.5.4:\n",
      "      Successfully uninstalled google-generativeai-0.5.4\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-generativeai-0.8.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-llms-gemini 0.3.7 requires google-generativeai<0.6.0,>=0.5.2, but you have google-generativeai 0.8.4 which is incompatible.\n",
      "llama-index-llms-gemini 0.3.7 requires pillow<11.0.0,>=10.2.0, but you have pillow 11.1.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers\n",
    "%pip install hf_xet\n",
    "%pip install openai==0.28\n",
    "%pip install -U google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: AIzaSyCZTGgHqRvNv2feTE370x6lVuSJLDRoVWQ\n",
      "models/chat-bison-001 - ['generateMessage', 'countMessageTokens']\n",
      "models/text-bison-001 - ['generateText', 'countTextTokens', 'createTunedTextModel']\n",
      "models/embedding-gecko-001 - ['embedText', 'countTextTokens']\n",
      "models/gemini-1.0-pro-vision-latest - ['generateContent', 'countTokens']\n",
      "models/gemini-pro-vision - ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-latest - ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-001 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-pro-002 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-pro - ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-latest - ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-001 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-flash-001-tuning - ['generateContent', 'countTokens', 'createTunedModel']\n",
      "models/gemini-1.5-flash - ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-002 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-flash-8b - ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-001 - ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-latest - ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-exp-0827 - ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-exp-0924 - ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-pro-exp-03-25 - ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-pro-preview-03-25 - ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-exp - ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash - ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-001 - ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-exp-image-generation - ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-lite-001 - ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-lite - ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 - ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-lite-preview - ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-pro-exp - ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-pro-exp-02-05 - ['generateContent', 'countTokens']\n",
      "models/gemini-exp-1206 - ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 - ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-thinking-exp - ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-thinking-exp-1219 - ['generateContent', 'countTokens']\n",
      "models/learnlm-1.5-pro-experimental - ['generateContent', 'countTokens']\n",
      "models/gemma-3-1b-it - ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it - ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it - ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it - ['generateContent', 'countTokens']\n",
      "models/embedding-001 - ['embedContent']\n",
      "models/text-embedding-004 - ['embedContent']\n",
      "models/gemini-embedding-exp-03-07 - ['embedContent']\n",
      "models/gemini-embedding-exp - ['embedContent']\n",
      "models/aqa - ['generateAnswer']\n",
      "models/imagen-3.0-generate-002 - ['predict']\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# retrieving the API key from the environment variable\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "print(\"API Key:\", gemini_api_key)\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "\n",
    "models = genai.list_models()\n",
    "for model in models:\n",
    "    print(model.name, \"-\", model.supported_generation_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized columns: Index(['feedback_id', 'employee_id', 'comment', 'role'], dtype='object')\n",
      "Analyzing sentiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis complete.\n",
      "Generating AI-powered responses...\n",
      "AI-powered responses generated.\n",
      "Processed data saved to processed_feedback.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import google.generativeai as genai\n",
    "sentiment_pipeline = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "# using gemma-3-4b-it model for generating responses due to free 30 tokens whereas other models have only 15 and get exhausted half way through the response.\n",
    "gemini_model = genai.GenerativeModel('models/gemma-3-4b-it') \n",
    "def generate_response(sentiment, comment):\n",
    "    # defining the prompt for the model to enhance the response generation\n",
    "    # The prompt is designed to guide the model in generating a response that is concise, professional, and relevant to the comment.\n",
    "    prompt = f\"\"\"\n",
    "You are a team lead providing short, professional feedback responses tailored to employee comments. \n",
    "Your responses should:\n",
    "- Be concise and professional.\n",
    "- Use a friendly and supportive tone.\n",
    "- Avoid overly formal language.\n",
    "- Be specific and relevant to the comment.\n",
    "- Use a maximum of 2 sentences.\n",
    "- Avoid using \"I\" or \"we\" in the response.\n",
    "- Avoid using \"you\" in the response.\n",
    "- Avoid repetitive phrases like \"That's fantastic to hear\" or \"Let's discuss.\"\n",
    "- Match the tone of the sentiment (positive, negative, or neutral).\n",
    "- Offer actionable suggestions for improvement when necessary.\n",
    "\n",
    "Based on these comments we are giving feedback to employees. \n",
    "\n",
    "\n",
    "Examples:\n",
    "- Comment: \"Great teamwork and collaboration!\"\n",
    "  Sentiment: Positive\n",
    "  Response: \"Your teamwork and collaboration are truly inspiring. Keep up the great work!\"\n",
    "\n",
    "- Comment: \"Needs improvement in meeting deadlines.\"\n",
    "  Sentiment: Negative\n",
    "  Response: \"Meeting deadlines is essential for success. Consider setting reminders and breaking tasks into smaller steps.\"\n",
    "\n",
    "- Comment: \"Could engage more during team discussions.\"\n",
    "  Sentiment: Neutral\n",
    "  Response: \"Active participation in discussions enhances team dynamics. I look forward to seeing your contributions grow.\"\n",
    "\n",
    "Now write a response for:\n",
    "- Comment: \"{comment}\"\n",
    "  Sentiment: {sentiment}\n",
    "  Response:\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = gemini_model.generate_content(prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Gemini API: {e}\")\n",
    "        return \"Error generating response.\"\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    # Normalize column names: strip whitespace and convert to lowercase to avoid issues with different formats\n",
    "    data.columns = data.columns.str.strip().str.lower()\n",
    "    return data\n",
    "\n",
    "def analyze_sentiment(comment):\n",
    "    result = sentiment_pipeline(comment)[0]  \n",
    "    label = result['label']  \n",
    "    return label\n",
    "\n",
    "def main(input_file, output_file):\n",
    "    data = load_data(input_file)\n",
    "    print(\"Normalized columns:\", data.columns)  # debugging statement\n",
    "    print(\"Analyzing sentiment...\")\n",
    "    data['sentiment'] = data['comment'].apply(analyze_sentiment)\n",
    "    print(\"Sentiment analysis complete.\")\n",
    "    print(\"Generating AI-powered responses...\")\n",
    "    data['ai_response'] = data.apply(lambda row: generate_response(row['sentiment'], row['comment']), axis=1)\n",
    "    print(\"AI-powered responses generated.\")\n",
    "    data.to_csv(output_file, index=False)\n",
    "    print(f\"Processed data saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"data.csv\" \n",
    "    output_file = \"processed_feedback.csv\"\n",
    "    main(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
